# ğŸ¤– JobAnalyzer

Analyseur automatique d'offres d'emploi Freelances avec intelligence artificielle.

âš ï¸ **Note Importante** : Ce projet est en dÃ©veloppement actif. Utilisez-le de maniÃ¨re Ã©thique et responsable.

## ğŸ“‹ Description

JobAnalyzer est un outil qui :
- Scrape automatiquement les nouvelles offres Freelances
- Nettoie et structure le HTML des offres (96% de rÃ©duction)
- Analyse et catÃ©gorise les offres avec l'IA (DeepSeek)
- Stocke les donnÃ©es de maniÃ¨re structurÃ©e dans Redis
- Fournit des analyses de marchÃ© et des tendances

L'avantage de l'IA sera qu'elle peut pÃ©rÃ©niser les technos

## âš ï¸ Avertissements

- Respectez les conditions d'utilisation des sites sources
- Ne partagez JAMAIS vos clÃ©s API (DeepSeek)
- Utilisez le rate limiting pour ne pas surcharger les sites
- Les donnÃ©es scrappÃ©es doivent Ãªtre utilisÃ©es de maniÃ¨re Ã©thique

## ğŸ— Architecture

### Backend (Python)
- Multi-source scraping (Beautiful Soup)
  - Free-Work (ImplÃ©mentÃ©)
  - Malt (Ã€ venir)
  - Comet (Ã€ venir)
- Analyse IA (DeepSeek)
- Cache (Redis)
- Orchestration (Airflow)

### Pipeline de DonnÃ©es
1. **DAG 01 - Scraping** (`01_JOB_SCRAPING_dag.py`)
   - Extraction des URLs d'offres
   - Scraping du HTML dÃ©taillÃ©
   - Mise en cache Redis

2. **DAG 02 - Transformation** (`02_JOB_TRANSFO.py`)
   - Nettoyage du HTML (96% de rÃ©duction)
   - Analyse IA avec DeepSeek
   - Stockage structurÃ©

## ğŸ›  Technologies

- **Backend** : Python 3.10
- **Scraping** : Beautiful Soup 4
- **Cache** : Redis
- **IA** : DeepSeek
- **Orchestration** : Apache Airflow
- **Conteneurisation** : Docker & Docker Compose

## ğŸ“¦ Structure du Projet

```
JobAnalyzer/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ airflow/           
â”‚   â”‚   â”œâ”€â”€ dags/         # DAGs Airflow
â”‚   â”‚   â”‚   â”œâ”€â”€ 01_JOB_SCRAPING_dag.py
â”‚   â”‚   â”‚   â””â”€â”€ 02_JOB_TRANSFO.py
â”‚   â”‚   â””â”€â”€ logs/        # Logs applicatifs
â”‚   â”œâ”€â”€ scraper/          
â”‚   â”‚   â”œâ”€â”€ config/       # Configuration et settings
â”‚   â”‚   â”œâ”€â”€ core/         # Composants principaux
â”‚   â”‚   â”‚   â”œâ”€â”€ list_scraper.py    # Extraction des URLs
â”‚   â”‚   â”‚   â”œâ”€â”€ job_scraper.py     # Scraping dÃ©taillÃ©
â”‚   â”‚   â”‚   â”œâ”€â”€ job_analyzer.py    # Analyse DeepSeek
â”‚   â”‚   â”‚   â”œâ”€â”€ html_cleaner.py    # Nettoyage HTML
â”‚   â”‚   â”‚   â””â”€â”€ cache.py           # Gestion Redis
â”‚   â”‚   â””â”€â”€ tests/        # Tests unitaires
â”‚   â””â”€â”€ models/           # ModÃ¨les de donnÃ©es
â”œâ”€â”€ docker/              
â”‚   â””â”€â”€ airflow/         # Configuration Airflow
â””â”€â”€ scripts/             # Scripts utilitaires
```

## ğŸ”’ SÃ©curitÃ©

1. **Variables d'environnement**
   - Ne JAMAIS commiter le fichier `.env`
   - Utiliser `.env.example` comme modÃ¨le
   - Stocker les secrets de maniÃ¨re sÃ©curisÃ©e

2. **Rate Limiting**
   - Respecter les limites d'API
   - DÃ©lais configurables entre les requÃªtes
   - Gestion des erreurs avec retry

## ğŸš€ Installation

1. **PrÃ©requis**
   - Docker & Docker Compose
   - ClÃ© API DeepSeek

2. **Configuration**
   ```bash
   # Copier le fichier d'exemple
   cp .env.example .env
   
   # Configurer dans .env :
   DEEPSEEK_API_KEY=votre_clÃ©_api
   ```

3. **Lancement**
   ```bash
   # Construction et dÃ©marrage
   docker compose up --build

   # VÃ©rification des services
   docker compose ps
   ```

## ğŸ”„ Pipeline de DonnÃ©es

1. **Scraping (DAG 01)**
   - Extraction quotidienne des nouvelles offres
   - Gestion intelligente de la pagination
   - Mise en cache Redis avec dÃ©duplication

2. **Transformation (DAG 02)**
   - Nettoyage HTML optimisÃ© (96% de rÃ©duction)
   - Analyse sÃ©mantique par DeepSeek
   - Logs dÃ©taillÃ©s de chaque Ã©tape

## ğŸ“Š Performances Actuelles

- **Scraping** : ~30 offres en 2-3 minutes
- **Nettoyage HTML** : 96% de rÃ©duction de taille
- **Analyse IA** : ~4 secondes par offre
- **Pipeline complet** : ~2 minutes pour 29 offres

## ğŸ“ TODO

- [x] ImplÃ©mentation du scraper Free-Work
- [x] IntÃ©gration DeepSeek
- [x] Pipeline de transformation
- [x] Logging avancÃ©
- [ ] Tests automatisÃ©s
- [ ] Support Malt
- [ ] Support Comet
- [ ] API REST
- [ ] Interface utilisateur

## ğŸ“œ Licence

MIT License - Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails. 