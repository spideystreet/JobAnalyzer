# ğŸ¤– JobAnalyzer

Analyseur automatique d'offres d'emploi Freelances avec intelligence artificielle.

âš ï¸ **Note Importante** : Ce projet est en dÃ©veloppement actif. Utilisez-le de maniÃ¨re Ã©thique et responsable.

## ğŸ“‹ Description

JobAnalyzer est un outil qui :
- Scrape automatiquement les nouvelles offres Freelances
- Analyse et catÃ©gorise les offres avec l'IA (DeepSeek v3)
- Stocke les donnÃ©es de maniÃ¨re structurÃ©e
- Fournit des analyses de marchÃ© et des tendances

## âš ï¸ Avertissements

- Respectez les conditions d'utilisation des sites sources
- Ne partagez JAMAIS vos clÃ©s API (OpenAI, Supabase)
- Utilisez le rate limiting pour ne pas surcharger les sites
- Les donnÃ©es scrappÃ©es doivent Ãªtre utilisÃ©es de maniÃ¨re Ã©thique

## ğŸ— Architecture

### Backend (Python)
- Scraping automatisÃ© (Beautiful Soup)
- Analyse IA (DeepSeek v3)
- Base de donnÃ©es (Supabase)

### Frontend (React)
- Dashboard interactif
- Visualisation des donnÃ©es
- Filtres avancÃ©s

## ğŸ›  Technologies

- **Backend** : Python 3.11
- **Frontend** : React
- **Base de donnÃ©es** : Supabase (PostgreSQL)
- **IA** : DeepSeek v3
- **DÃ©ploiement** : Google Cloud Run, Vercel

## ğŸ“¦ Structure du Projet

```
JobAnalyzer/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ scraper/        # Scraping FreeWork
â”‚   â”œâ”€â”€ models/         # ModÃ¨les de donnÃ©es
â”‚   â””â”€â”€ database/       # Client Supabase
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â””â”€â”€ public/
â””â”€â”€ docker/            # Configuration Docker
```

## ğŸ”’ SÃ©curitÃ©

1. **Variables d'environnement**
   - Ne JAMAIS commiter le fichier `.env`
   - Utiliser `.env.example` comme modÃ¨le
   - Stocker les secrets de maniÃ¨re sÃ©curisÃ©e

2. **Rate Limiting**
   - Respecter les limites d'API
   - ImplÃ©menter des dÃ©lais entre les requÃªtes
   - GÃ©rer les erreurs de maniÃ¨re gracieuse

## ğŸš€ Installation

1. **PrÃ©requis**
   - Python 3.11+
   - Docker
   - Node.js 18+
   - ClÃ©s API (voir ci-dessous)

2. **Configuration**
   ```bash
   # Ne JAMAIS commiter ce fichier
   cp .env.example .env
   
   # Configurer vos variables dans .env :
   # - OPENAI_API_KEY
   # - SUPABASE_URL
   # - SUPABASE_KEY
   ```

3. **Lancement**
   ```bash
   # DÃ©veloppement
   docker compose up --build

   # Production
   # Instructions Ã  venir
   ```

## ğŸ“Š Structure de la Base de DonnÃ©es

### Table `JOB_OFFERS`
- Stockage des offres d'emploi
- Classification par domaine
- Analyse IA
- Informations gÃ©ographiques

## ğŸ”„ Workflow

1. Scraping quotidien des nouvelles offres
2. Analyse et enrichissement par IA
3. Stockage structurÃ©
4. Mise Ã  jour du dashboard

## ğŸ“ TODO

- [ ] ImplÃ©mentation du scraper
- [ ] IntÃ©gration OpenAI
- [ ] Configuration Cloud Run
- [ ] DÃ©veloppement frontend
- [ ] Tests automatisÃ©s
- [ ] Documentation complÃ¨te
- [ ] Guide de contribution
- [ ] SÃ©curisation des endpoints

## ğŸ¤ Contribution

Nous accueillons les contributions ! Merci de :
- CrÃ©er une issue avant de commencer
- Suivre les conventions de code
- Ajouter des tests pour les nouvelles fonctionnalitÃ©s
- Respecter l'Ã©thique et la lÃ©galitÃ© du scraping

## ğŸ“œ Licence

MIT License - Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails. 