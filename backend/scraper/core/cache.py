"""
Module de gestion du cache Redis pour le suivi des offres trait√©es.
"""

from datetime import datetime
from typing import Optional
from redis import Redis
from loguru import logger

from ..config.settings import (
    REDIS_HOST,
    REDIS_PORT,
    REDIS_DB,
    CACHE_TTL
)

class JobCache:
    """
    Gestion du cache Redis pour le suivi des offres d'emploi trait√©es.
    Utilise Redis pour stocker les URLs avec un TTL de 48 heures.
    """

    def __init__(self):
        """Initialise la connexion Redis avec les param√®tres de configuration."""
        try:
            self.redis = Redis(
                host=REDIS_HOST,
                port=REDIS_PORT,
                db=REDIS_DB,
                decode_responses=True  # Pour avoir des str au lieu de bytes
            )
            logger.info(f"‚úÖ Connexion Redis √©tablie ({REDIS_HOST}:{REDIS_PORT})")
        except Exception as e:
            logger.error(f"‚ùå Erreur de connexion Redis: {str(e)}")
            raise

    def _get_key(self, url: str, prefix: str = "job") -> str:
        """
        G√©n√®re la cl√© Redis pour une URL.
        
        Args:
            url: L'URL de l'offre
            prefix: Pr√©fixe pour diff√©rencier les types de donn√©es
            
        Returns:
            str: La cl√© format√©e
        """
        return f"{prefix}:{url}"

    async def store_raw_html(self, url: str, html_content: str) -> None:
        """
        Stocke le HTML brut d'une offre dans Redis.
        
        Args:
            url: L'URL de l'offre
            html_content: Le contenu HTML brut √† stocker
        """
        try:
            # Utilise un pr√©fixe diff√©rent pour le HTML brut
            key = self._get_key(url, prefix="raw_html")
            self.redis.set(
                key,
                html_content,
                ex=CACHE_TTL
            )
            # Marque aussi l'URL comme trait√©e
            await self.mark_processed(url)
            logger.debug(f"‚úÖ HTML stock√© pour: {url}")
        except Exception as e:
            logger.error(f"‚ùå Erreur lors du stockage du HTML: {str(e)}")
            raise

    async def is_processed(self, url: str) -> bool:
        """
        V√©rifie si une URL a d√©j√† √©t√© trait√©e.
        
        Args:
            url: L'URL √† v√©rifier
            
        Returns:
            bool: True si l'URL est dans le cache
        """
        try:
            return bool(self.redis.exists(self._get_key(url)))
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la v√©rification du cache: {str(e)}")
            return False

    async def mark_processed(self, url: str) -> None:
        """
        Marque une URL comme trait√©e avec un TTL.
        
        Args:
            url: L'URL √† marquer
        """
        try:
            key = self._get_key(url)
            self.redis.set(
                key,
                str(datetime.now().timestamp()),
                ex=CACHE_TTL
            )
            logger.debug(f"‚úÖ URL marqu√©e comme trait√©e: {url}")
        except Exception as e:
            logger.error(f"‚ùå Erreur lors du marquage dans le cache: {str(e)}")

    async def get_last_processed_time(self, url: str) -> Optional[datetime]:
        """
        R√©cup√®re la derni√®re date de traitement d'une URL.
        
        Args:
            url: L'URL √† v√©rifier
            
        Returns:
            Optional[datetime]: La date de dernier traitement ou None
        """
        try:
            timestamp = self.redis.get(self._get_key(url))
            if timestamp:
                return datetime.fromtimestamp(float(timestamp))
            return None
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la r√©cup√©ration du timestamp: {str(e)}")
            return None

    def clear_cache(self) -> None:
        """Vide le cache (utile pour les tests)."""
        try:
            self.redis.flushdb()
            logger.warning("üóë Cache Redis vid√©")
        except Exception as e:
            logger.error(f"‚ùå Erreur lors du vidage du cache: {str(e)}")

    def close(self) -> None:
        """Ferme la connexion Redis."""
        try:
            self.redis.close()
            logger.info("üëã Connexion Redis ferm√©e")
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la fermeture de Redis: {str(e)}")

    async def get_all_raw_html_keys(self) -> list[str]:
        """
        R√©cup√®re toutes les cl√©s des HTML bruts stock√©s.
        
        Returns:
            list[str]: Liste des cl√©s raw_html
        """
        try:
            pattern = self._get_key("*", prefix="raw_html")
            keys = self.redis.keys(pattern)
            logger.debug(f"‚úÖ {len(keys)} cl√©s raw_html trouv√©es")
            return keys
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la r√©cup√©ration des cl√©s raw_html: {str(e)}")
            return []

    async def get_raw_html(self, key: str) -> Optional[str]:
        """
        R√©cup√®re le HTML brut pour une cl√© donn√©e.
        
        Args:
            key: La cl√© Redis compl√®te (raw_html:url)
            
        Returns:
            Optional[str]: Le contenu HTML ou None
        """
        try:
            content = self.redis.get(key)
            if content:
                logger.debug(f"‚úÖ HTML r√©cup√©r√© pour: {key}")
                return content
            return None
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la r√©cup√©ration du HTML: {str(e)}")
            return None

    async def store_analysis(self, key: str, analysis: dict) -> None:
        """
        Stocke le r√©sultat de l'analyse DeepSeek.
        
        Args:
            key: La cl√© Redis de l'offre (raw_html:url)
            analysis: Le dictionnaire contenant l'analyse
        """
        try:
            # Extrait l'URL de la cl√© raw_html:url
            url = key.split(":", 1)[1]
            
            # Ajoute l'URL √† l'analyse
            analysis['URL'] = url
            
            # Stocke avec le pr√©fixe analysis
            analysis_key = self._get_key(url, prefix="analysis")
            self.redis.set(
                analysis_key,
                str(analysis),  # Convertit le dict en str
                ex=CACHE_TTL
            )
            logger.debug(f"‚úÖ Analyse stock√©e pour: {url}")
        except Exception as e:
            logger.error(f"‚ùå Erreur lors du stockage de l'analyse: {str(e)}")
            raise

    async def store_cleaned_html(self, key: str, cleaned_html: str) -> None:
        """
        Stocke le HTML nettoy√© dans Redis.
        
        Args:
            key: La cl√© Redis de l'offre (raw_html:url)
            cleaned_html: Le contenu HTML nettoy√©
        """
        try:
            cleaned_key = key.replace('raw_html:', 'cleaned_html:')
            self.redis.set(cleaned_key, cleaned_html, ex=CACHE_TTL)
            logger.debug(f"‚úÖ HTML nettoy√© stock√© pour: {cleaned_key}")
        except Exception as e:
            logger.error(f"‚ùå Erreur lors du stockage du HTML nettoy√©: {str(e)}")
            raise

    async def get_cleaned_html(self, key: str) -> Optional[str]:
        """
        R√©cup√®re le HTML nettoy√© depuis Redis.
        
        Args:
            key: La cl√© Redis de l'offre (cleaned_html:url)
            
        Returns:
            Optional[str]: Le contenu HTML nettoy√© ou None
        """
        try:
            content = self.redis.get(key)
            if content:
                logger.debug(f"‚úÖ HTML nettoy√© r√©cup√©r√© pour: {key}")
                return content
            return None
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la r√©cup√©ration du HTML nettoy√©: {str(e)}")
            return None

    async def get_all_cleaned_html_keys(self) -> list[str]:
        """
        R√©cup√®re toutes les cl√©s des HTML nettoy√©s.
        
        Returns:
            list[str]: Liste des cl√©s cleaned_html
        """
        try:
            pattern = self._get_key("*", prefix="cleaned_html")
            keys = self.redis.keys(pattern)
            logger.debug(f"‚úÖ {len(keys)} cl√©s cleaned_html trouv√©es")
            return keys
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la r√©cup√©ration des cl√©s cleaned_html: {str(e)}")
            return []

    async def get_all_analysis_keys(self) -> list[str]:
        """
        R√©cup√®re toutes les cl√©s des analyses stock√©es.
        
        Returns:
            list[str]: Liste des cl√©s analysis
        """
        try:
            pattern = self._get_key("*", prefix="analysis")
            keys = self.redis.keys(pattern)
            logger.debug(f"‚úÖ {len(keys)} cl√©s analysis trouv√©es")
            return keys
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la r√©cup√©ration des cl√©s analysis: {str(e)}")
            return []

    async def get_analysis(self, key: str) -> Optional[dict]:
        """
        R√©cup√®re une analyse depuis Redis.
        
        Args:
            key: La cl√© Redis de l'analyse (analysis:url)
            
        Returns:
            Optional[dict]: Le dictionnaire d'analyse ou None
        """
        try:
            content = self.redis.get(key)
            if content:
                logger.debug(f"‚úÖ Analyse r√©cup√©r√©e pour: {key}")
                return eval(content)  # Convertit la str en dict
            return None
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la r√©cup√©ration de l'analyse: {str(e)}")
            return None

    async def delete_analysis(self, key: str) -> bool:
        """
        Supprime une analyse de Redis apr√®s son chargement dans Supabase.
        
        Args:
            key: La cl√© Redis de l'analyse (analysis:url)
            
        Returns:
            bool: True si supprim√© avec succ√®s
        """
        try:
            deleted = self.redis.delete(key)
            if deleted:
                logger.debug(f"‚úÖ Analyse supprim√©e: {key}")
                return True
            return False
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la suppression de l'analyse: {str(e)}")
            return False